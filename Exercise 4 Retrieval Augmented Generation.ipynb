{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1d1a38d-9ffd-40f3-885a-149c993148b5",
   "metadata": {},
   "source": [
    "![ALT_TEXT_FOR_SCREEN_READERS](./header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460200ed-97ba-4cdf-bc86-b29f6a37129d",
   "metadata": {},
   "source": [
    "# Exercise 4 Retrieval Augmented Generation\n",
    "\n",
    "The goal of this exercise is to build a chatbot demo which allows you to talk about the content of documents. The method behind this exercise is called retrieval augmented generation (RAG).\n",
    "The detailed tasks in this exercise are:\n",
    "- install a local large language model using the application LM Studio\n",
    "- setup a new environment with the required packages\n",
    "- implement a simple chatbot using llama-index\n",
    "- test the chatbot on a specific technical document\n",
    "\n",
    "Sources for llama-index and local LLM [1] using LM Studio [2] and a small LLM [3]:\n",
    "- [1] [https://docs.llamaindex.ai/en/stable/getting_started/starter_example_local/?h=embedding+model](llama-index)\n",
    "- [2] [https://lmstudio.ai/](https://lmstudio.ai/)\n",
    "- [3] [https://huggingface.co/models](https://huggingface.co/models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8188dcaa-d1b5-4eb5-9abd-2349632e0ed8",
   "metadata": {},
   "source": [
    "# Considerations\n",
    "\n",
    "- Read the tutorials carefully, especially [1]\n",
    "- Install LM Studio\n",
    "- Install additional software packages into the environment by uncommenting the pip install commands one time\n",
    "- Select a model based on your memory size of the laptop\n",
    "- This is less a coding example, rather just the integration with a local LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f217f1-0006-4b8a-9ebc-e745c2a2ae4f",
   "metadata": {},
   "source": [
    "# Requirements\n",
    "\n",
    "- R0: Install the required packages using the pip commands\n",
    "- R1: Install the LM Studio\n",
    "- R2: Find a model which is running on your machine\n",
    "- R3: Start the server for the model in LM Studio\n",
    "- R4: Connect the server to the notebook\n",
    "- R5: Run the code parts until the first query\n",
    "- R6: Improve your query according to the slides learned in the class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39153d5e-e2e0-426f-95dc-8b6a9cc4d83e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7507c7-d643-47d2-bf7b-dd2a7b1dc972",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c81316-7512-4ce3-a944-b710e86f4c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a7b412-1389-4222-a3eb-4f7800a7f567",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pip install llama-index-llms-openai-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22faf1e2-3add-4e53-9a11-4c563193fbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48544301-2bfe-4442-97be-2543fb3254e9",
   "metadata": {},
   "source": [
    "# Code Snipplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c37b862-ebb5-4ed0-868e-bc6b92490ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai_like import OpenAILike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e419b49-23fa-471b-aeb2-a1a59e021b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b431455c-6fdd-4847-9b60-7c34cbf8c097",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327f7fa5-4905-4e0a-a776-67015efdc718",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.embeddings import resolve_embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff01f272-4257-4def-ba77-bd8122105378",
   "metadata": {},
   "source": [
    "## Prepare LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0da421-c591-4822-8a9b-d392b53d3d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_url = 'http://localhost:1234/v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2807ab-7a73-460d-bf12-4c1c369698c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = OpenAILike(model=\"mistral\", temperature=0.0, api_key='bla', api_base=llm_url, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffef1a13-6bfd-43db-934c-0fe0baa65fcb",
   "metadata": {},
   "source": [
    "## Prepare Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2787f9a8-bc0e-4931-a29d-1d6042a16250",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en\",cache_folder='./')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e03faa6-48d7-40d5-a787-a019d576b713",
   "metadata": {},
   "source": [
    "## Generate Vector Store Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d42e15-7828-432f-8973-be553c0e59b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"documents\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e535caac-48f4-4385-86e9-567e0a1e692c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258e338f-444a-458d-872a-7848ffabc685",
   "metadata": {},
   "source": [
    "## Setup Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf259f0-81df-4cdc-8586-76efdad8eab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(streaming=False, verbose=True, similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90e85ef-a1e0-4b45-b7bb-b103558ca999",
   "metadata": {},
   "source": [
    "## First Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e770283-8a1f-4037-957e-326bcf7f0e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"What are the physical properties of the product?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420aafe7-afbf-4f2f-ab46-8556c2ea1cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a0ad60-45bb-4e04-ab62-917c0c485fcd",
   "metadata": {},
   "source": [
    "# Improved Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78d7d71-8844-45d3-b64f-b19f0be6b1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
